<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>data.datasets.multi_modal_img_text package &mdash; CVNets: A library for training computer vision networks  documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            CVNets: A library for training computer vision networks
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Table of Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sample_recipes.html">Sample Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../how_to.html">How To</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data_samplers.html">Data Samplers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../en/general/README-model-zoo.html">Model Zoo</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">CVNets: A library for training computer vision networks</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">data.datasets.multi_modal_img_text package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/autogen/data.datasets.multi_modal_img_text.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="data-datasets-multi-modal-img-text-package">
<h1>data.datasets.multi_modal_img_text package<a class="headerlink" href="#data-datasets-multi-modal-img-text-package" title="Permalink to this heading"></a></h1>
<section id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this heading"></a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="data.datasets.multi_modal_img_text.zero_shot.html">data.datasets.multi_modal_img_text.zero_shot package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="data.datasets.multi_modal_img_text.zero_shot.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="data.datasets.multi_modal_img_text.zero_shot.html#module-data.datasets.multi_modal_img_text.zero_shot.base_zero_shot">data.datasets.multi_modal_img_text.zero_shot.base_zero_shot module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="data.datasets.multi_modal_img_text.zero_shot.html#data.datasets.multi_modal_img_text.zero_shot.base_zero_shot.BaseZeroShotDataset"><code class="docutils literal notranslate"><span class="pre">BaseZeroShotDataset</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="data.datasets.multi_modal_img_text.zero_shot.html#data.datasets.multi_modal_img_text.zero_shot.base_zero_shot.BaseZeroShotDataset.__init__"><code class="docutils literal notranslate"><span class="pre">BaseZeroShotDataset.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="data.datasets.multi_modal_img_text.zero_shot.html#data.datasets.multi_modal_img_text.zero_shot.base_zero_shot.BaseZeroShotDataset.add_arguments"><code class="docutils literal notranslate"><span class="pre">BaseZeroShotDataset.add_arguments()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="data.datasets.multi_modal_img_text.zero_shot.html#data.datasets.multi_modal_img_text.zero_shot.base_zero_shot.BaseZeroShotDataset.class_names"><code class="docutils literal notranslate"><span class="pre">BaseZeroShotDataset.class_names()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="data.datasets.multi_modal_img_text.zero_shot.html#data.datasets.multi_modal_img_text.zero_shot.base_zero_shot.BaseZeroShotDataset.generate_text_prompts"><code class="docutils literal notranslate"><span class="pre">BaseZeroShotDataset.generate_text_prompts()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="data.datasets.multi_modal_img_text.zero_shot.html#module-data.datasets.multi_modal_img_text.zero_shot.imagenet">data.datasets.multi_modal_img_text.zero_shot.imagenet module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="data.datasets.multi_modal_img_text.zero_shot.html#data.datasets.multi_modal_img_text.zero_shot.imagenet.ImageNetDatasetZeroShot"><code class="docutils literal notranslate"><span class="pre">ImageNetDatasetZeroShot</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="data.datasets.multi_modal_img_text.zero_shot.html#data.datasets.multi_modal_img_text.zero_shot.imagenet.ImageNetDatasetZeroShot.__init__"><code class="docutils literal notranslate"><span class="pre">ImageNetDatasetZeroShot.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="data.datasets.multi_modal_img_text.zero_shot.html#data.datasets.multi_modal_img_text.zero_shot.imagenet.ImageNetDatasetZeroShot.class_names"><code class="docutils literal notranslate"><span class="pre">ImageNetDatasetZeroShot.class_names()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="data.datasets.multi_modal_img_text.zero_shot.html#data.datasets.multi_modal_img_text.zero_shot.imagenet.ImageNetDatasetZeroShot.generate_text_prompts"><code class="docutils literal notranslate"><span class="pre">ImageNetDatasetZeroShot.generate_text_prompts()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="data.datasets.multi_modal_img_text.zero_shot.html#module-data.datasets.multi_modal_img_text.zero_shot.imagenet_class_names">data.datasets.multi_modal_img_text.zero_shot.imagenet_class_names module</a></li>
<li class="toctree-l2"><a class="reference internal" href="data.datasets.multi_modal_img_text.zero_shot.html#module-data.datasets.multi_modal_img_text.zero_shot.templates">data.datasets.multi_modal_img_text.zero_shot.templates module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="data.datasets.multi_modal_img_text.zero_shot.html#data.datasets.multi_modal_img_text.zero_shot.templates.generate_text_prompts_clip"><code class="docutils literal notranslate"><span class="pre">generate_text_prompts_clip()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="data.datasets.multi_modal_img_text.zero_shot.html#module-data.datasets.multi_modal_img_text.zero_shot">Module contents</a><ul>
<li class="toctree-l3"><a class="reference internal" href="data.datasets.multi_modal_img_text.zero_shot.html#data.datasets.multi_modal_img_text.zero_shot.arguments_zero_shot_dataset"><code class="docutils literal notranslate"><span class="pre">arguments_zero_shot_dataset()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="data.datasets.multi_modal_img_text.zero_shot.html#data.datasets.multi_modal_img_text.zero_shot.build_zero_shot_dataset"><code class="docutils literal notranslate"><span class="pre">build_zero_shot_dataset()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</section>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this heading"></a></h2>
</section>
<section id="module-data.datasets.multi_modal_img_text.base_multi_modal_img_text">
<span id="data-datasets-multi-modal-img-text-base-multi-modal-img-text-module"></span><h2>data.datasets.multi_modal_img_text.base_multi_modal_img_text module<a class="headerlink" href="#module-data.datasets.multi_modal_img_text.base_multi_modal_img_text" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="data.datasets.multi_modal_img_text.base_multi_modal_img_text.BaseMultiModalImgText">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">data.datasets.multi_modal_img_text.base_multi_modal_img_text.</span></span><span class="sig-name descname"><span class="pre">BaseMultiModalImgText</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opts</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/datasets/multi_modal_img_text/base_multi_modal_img_text.html#BaseMultiModalImgText"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#data.datasets.multi_modal_img_text.base_multi_modal_img_text.BaseMultiModalImgText" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="data.datasets.html#data.datasets.dataset_base.BaseImageDataset" title="data.datasets.dataset_base.BaseImageDataset"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseImageDataset</span></code></a></p>
<p>Base class for Image-Text multi-modal learning</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>opts</strong> – command-line arguments</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="data.datasets.multi_modal_img_text.base_multi_modal_img_text.BaseMultiModalImgText.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opts</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/data/datasets/multi_modal_img_text/base_multi_modal_img_text.html#BaseMultiModalImgText.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#data.datasets.multi_modal_img_text.base_multi_modal_img_text.BaseMultiModalImgText.__init__" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="data.datasets.multi_modal_img_text.base_multi_modal_img_text.BaseMultiModalImgText.get_zero_shot_dataset">
<span class="sig-name descname"><span class="pre">get_zero_shot_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><a class="reference internal" href="data.datasets.multi_modal_img_text.zero_shot.html#data.datasets.multi_modal_img_text.zero_shot.base_zero_shot.BaseZeroShotDataset" title="data.datasets.multi_modal_img_text.zero_shot.base_zero_shot.BaseZeroShotDataset"><span class="pre">BaseZeroShotDataset</span></a><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/data/datasets/multi_modal_img_text/base_multi_modal_img_text.html#BaseMultiModalImgText.get_zero_shot_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#data.datasets.multi_modal_img_text.base_multi_modal_img_text.BaseMultiModalImgText.get_zero_shot_dataset" title="Permalink to this definition"></a></dt>
<dd><p>If zero-shot evaluation is enabled, zero-shot dataset is returned.
Otherwise, None is returned</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="data.datasets.multi_modal_img_text.base_multi_modal_img_text.BaseMultiModalImgText.get_dataset">
<span class="sig-name descname"><span class="pre">get_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Any</span></span></span><a class="reference internal" href="../_modules/data/datasets/multi_modal_img_text/base_multi_modal_img_text.html#BaseMultiModalImgText.get_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#data.datasets.multi_modal_img_text.base_multi_modal_img_text.BaseMultiModalImgText.get_dataset" title="Permalink to this definition"></a></dt>
<dd><p>Helper function to get the dataset. Child classes must override this function</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="data.datasets.multi_modal_img_text.base_multi_modal_img_text.BaseMultiModalImgText.share_dataset_arguments">
<span class="sig-name descname"><span class="pre">share_dataset_arguments</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/data/datasets/multi_modal_img_text/base_multi_modal_img_text.html#BaseMultiModalImgText.share_dataset_arguments"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#data.datasets.multi_modal_img_text.base_multi_modal_img_text.BaseMultiModalImgText.share_dataset_arguments" title="Permalink to this definition"></a></dt>
<dd><p>Returns the number of classes in detection dataset along with super-class arguments.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="data.datasets.multi_modal_img_text.base_multi_modal_img_text.BaseMultiModalImgText.add_arguments">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">add_arguments</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parser</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ArgumentParser</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ArgumentParser</span></span></span><a class="reference internal" href="../_modules/data/datasets/multi_modal_img_text/base_multi_modal_img_text.html#BaseMultiModalImgText.add_arguments"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#data.datasets.multi_modal_img_text.base_multi_modal_img_text.BaseMultiModalImgText.add_arguments" title="Permalink to this definition"></a></dt>
<dd><p>Add dataset-specific arguments to the parser.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="data.datasets.multi_modal_img_text.base_multi_modal_img_text.BaseMultiModalImgText.get_zero_shot_pair">
<span class="sig-name descname"><span class="pre">get_zero_shot_pair</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Image</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/data/datasets/multi_modal_img_text/base_multi_modal_img_text.html#BaseMultiModalImgText.get_zero_shot_pair"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#data.datasets.multi_modal_img_text.base_multi_modal_img_text.BaseMultiModalImgText.get_zero_shot_pair" title="Permalink to this definition"></a></dt>
<dd><p>Get image-text pair for zero-shot dataset along with classification label.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>img_index</strong> – Image index</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tuple of PIL image, captions, and class label</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="data.datasets.multi_modal_img_text.base_multi_modal_img_text.BaseMultiModalImgText.get_dataset_pair">
<span class="sig-name descname"><span class="pre">get_dataset_pair</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Any</span></span></span><a class="reference internal" href="../_modules/data/datasets/multi_modal_img_text/base_multi_modal_img_text.html#BaseMultiModalImgText.get_dataset_pair"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#data.datasets.multi_modal_img_text.base_multi_modal_img_text.BaseMultiModalImgText.get_dataset_pair" title="Permalink to this definition"></a></dt>
<dd><p>Get image-text pair from the dataset. Sub-classes must implement this method.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="data.datasets.multi_modal_img_text.base_multi_modal_img_text.BaseMultiModalImgText.extra_repr">
<span class="sig-name descname"><span class="pre">extra_repr</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="reference internal" href="../_modules/data/datasets/multi_modal_img_text/base_multi_modal_img_text.html#BaseMultiModalImgText.extra_repr"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#data.datasets.multi_modal_img_text.base_multi_modal_img_text.BaseMultiModalImgText.extra_repr" title="Permalink to this definition"></a></dt>
<dd><p>Extra information to be represented in __repr__. Each line in the output
string should be prefixed with <code class="docutils literal notranslate"><span class="pre">\t</span></code>.</p>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="data.datasets.multi_modal_img_text.base_multi_modal_img_text.multi_modal_img_text_collate_fn">
<span class="sig-prename descclassname"><span class="pre">data.datasets.multi_modal_img_text.base_multi_modal_img_text.</span></span><span class="sig-name descname"><span class="pre">multi_modal_img_text_collate_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">opts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Namespace</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Mapping</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">Tensor</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/data/datasets/multi_modal_img_text/base_multi_modal_img_text.html#multi_modal_img_text_collate_fn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#data.datasets.multi_modal_img_text.base_multi_modal_img_text.multi_modal_img_text_collate_fn" title="Permalink to this definition"></a></dt>
<dd><p>Combines a list of dictionaries into a single dictionary by concatenating matching fields.</p>
</dd></dl>

</section>
<section id="module-data.datasets.multi_modal_img_text.flickr">
<span id="data-datasets-multi-modal-img-text-flickr-module"></span><h2>data.datasets.multi_modal_img_text.flickr module<a class="headerlink" href="#module-data.datasets.multi_modal_img_text.flickr" title="Permalink to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="data.datasets.multi_modal_img_text.flickr.FlickrDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">data.datasets.multi_modal_img_text.flickr.</span></span><span class="sig-name descname"><span class="pre">FlickrDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opts</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/datasets/multi_modal_img_text/flickr.html#FlickrDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#data.datasets.multi_modal_img_text.flickr.FlickrDataset" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#data.datasets.multi_modal_img_text.base_multi_modal_img_text.BaseMultiModalImgText" title="data.datasets.multi_modal_img_text.base_multi_modal_img_text.BaseMultiModalImgText"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseMultiModalImgText</span></code></a></p>
<p>Dataset loader for Flickr-30k and Flickr-8k datasets.</p>
<dl class="simple">
<dt>For more info see:</dt><dd><p><a class="reference external" href="http://hockenmaier.cs.illinois.edu/8k-pictures.html">http://hockenmaier.cs.illinois.edu/8k-pictures.html</a>
<a class="reference external" href="https://shannon.cs.illinois.edu/DenotationGraph/">https://shannon.cs.illinois.edu/DenotationGraph/</a></p>
</dd>
<dt>Splits: train, val, and test</dt><dd><p>Also known in literature as Karpathy splits
<a class="reference external" href="https://cs.stanford.edu/people/karpathy/deepimagesent/">https://cs.stanford.edu/people/karpathy/deepimagesent/</a></p>
</dd>
<dt>Tracking license info:</dt><dd><p>Captions have CC BY 3.0 license (see links above).
Splits are under BSD License (see Github of NeuralTalk by Karpathy et. al.).
Images are from Flickr. We do not own them and are only used for research purposes.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>opts</strong> – command-line arguments</p></li>
<li><p><strong>is_training</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) – A flag used to indicate training or
validation mode. Default: True</p></li>
<li><p><strong>is_evaluation</strong> (<em>Optional</em><em>[</em><em>bool</em><em>]</em>) – A flag used to indicate evaluation (or
inference) mode. Default: False</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="data.datasets.multi_modal_img_text.flickr.FlickrDataset.get_dataset">
<span class="sig-name descname"><span class="pre">get_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/data/datasets/multi_modal_img_text/flickr.html#FlickrDataset.get_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#data.datasets.multi_modal_img_text.flickr.FlickrDataset.get_dataset" title="Permalink to this definition"></a></dt>
<dd><p>The data under <cite>self.root</cite> is expected to consist of:</p>
<blockquote>
<div><p>dataset.json   # Karpathy splits + captions
images/        # Raw images</p>
</div></blockquote>
<dl class="simple">
<dt>The metdatadata cap be downloaded from:</dt><dd><p><a class="reference external" href="https://cs.stanford.edu/people/karpathy/deepimagesent/flickr30k.zip">https://cs.stanford.edu/people/karpathy/deepimagesent/flickr30k.zip</a></p>
</dd>
<dt>Images can be obtained from:</dt><dd><p>Flickr-8k:  <a class="reference external" href="http://hockenmaier.cs.illinois.edu/8k-pictures.html">http://hockenmaier.cs.illinois.edu/8k-pictures.html</a>
Flickr-30k: <a class="reference external" href="https://shannon.cs.illinois.edu/DenotationGraph/">https://shannon.cs.illinois.edu/DenotationGraph/</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-data.datasets.multi_modal_img_text.img_text_tar_dataset">
<span id="data-datasets-multi-modal-img-text-img-text-tar-dataset-module"></span><h2>data.datasets.multi_modal_img_text.img_text_tar_dataset module<a class="headerlink" href="#module-data.datasets.multi_modal_img_text.img_text_tar_dataset" title="Permalink to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="data.datasets.multi_modal_img_text.img_text_tar_dataset.extract_content">
<span class="sig-prename descclassname"><span class="pre">data.datasets.multi_modal_img_text.img_text_tar_dataset.</span></span><span class="sig-name descname"><span class="pre">extract_content</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tar_file</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">TarFile</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">file_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">AnyStr</span></span></span><a class="reference internal" href="../_modules/data/datasets/multi_modal_img_text/img_text_tar_dataset.html#extract_content"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#data.datasets.multi_modal_img_text.img_text_tar_dataset.extract_content" title="Permalink to this definition"></a></dt>
<dd><p>Extract the context of a particular file inside a tar file and returns it.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="data.datasets.multi_modal_img_text.img_text_tar_dataset.decode_image">
<span class="sig-prename descclassname"><span class="pre">data.datasets.multi_modal_img_text.img_text_tar_dataset.</span></span><span class="sig-name descname"><span class="pre">decode_image</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">byte_data</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Image</span></span></span><a class="reference internal" href="../_modules/data/datasets/multi_modal_img_text/img_text_tar_dataset.html#decode_image"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#data.datasets.multi_modal_img_text.img_text_tar_dataset.decode_image" title="Permalink to this definition"></a></dt>
<dd><p>Reads the byte image data and returns the PIL image.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="data.datasets.multi_modal_img_text.img_text_tar_dataset.decode_text">
<span class="sig-prename descclassname"><span class="pre">data.datasets.multi_modal_img_text.img_text_tar_dataset.</span></span><span class="sig-name descname"><span class="pre">decode_text</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">byte_data</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">str</span></span></span><a class="reference internal" href="../_modules/data/datasets/multi_modal_img_text/img_text_tar_dataset.html#decode_text"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#data.datasets.multi_modal_img_text.img_text_tar_dataset.decode_text" title="Permalink to this definition"></a></dt>
<dd><p>Reads the byte text data and returns the decoded string.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="data.datasets.multi_modal_img_text.img_text_tar_dataset.async_download_file_from_s3">
<span class="sig-prename descclassname"><span class="pre">data.datasets.multi_modal_img_text.img_text_tar_dataset.</span></span><span class="sig-name descname"><span class="pre">async_download_file_from_s3</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opts</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Namespace</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tar_file_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_loc</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/data/datasets/multi_modal_img_text/img_text_tar_dataset.html#async_download_file_from_s3"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#data.datasets.multi_modal_img_text.img_text_tar_dataset.async_download_file_from_s3" title="Permalink to this definition"></a></dt>
<dd><p>Helper function to download the files asynchronously from S3.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>opts</strong> – command-line arguments</p></li>
<li><p><strong>tar_file_name</strong> – Name of the tar file</p></li>
<li><p><strong>cache_loc</strong> – Caching location on the local machine</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="data.datasets.multi_modal_img_text.img_text_tar_dataset.ImgTextTarDataset">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">data.datasets.multi_modal_img_text.img_text_tar_dataset.</span></span><span class="sig-name descname"><span class="pre">ImgTextTarDataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opts</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/data/datasets/multi_modal_img_text/img_text_tar_dataset.html#ImgTextTarDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#data.datasets.multi_modal_img_text.img_text_tar_dataset.ImgTextTarDataset" title="Permalink to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#data.datasets.multi_modal_img_text.base_multi_modal_img_text.BaseMultiModalImgText" title="data.datasets.multi_modal_img_text.base_multi_modal_img_text.BaseMultiModalImgText"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseMultiModalImgText</span></code></a></p>
<p>ImgTextTarDataset class for datasets that store Image-Text pairs as tar files, each tar file with multiple pairs.</p>
<p>The dataset should be stored in following format where <cite>img_text_tar_dataset</cite> is the location of directory that
has all tar files.</p>
<p>img_text_tar_dataset
<a href="#id1"><span class="problematic" id="id2">|</span></a>— 00000000_0_1000.tar.gz
<a href="#id3"><span class="problematic" id="id4">|</span></a>——– 00000000_0_image
<a href="#id5"><span class="problematic" id="id6">|</span></a>——– 00000000_0_text
<a href="#id7"><span class="problematic" id="id8">|</span></a>——– 00000000_1_image
<a href="#id9"><span class="problematic" id="id10">|</span></a>——– 00000000_1_text
<a href="#id11"><span class="problematic" id="id12">|</span></a>——– …</p>
<p><a href="#id13"><span class="problematic" id="id14">|</span></a>— 00000000_1000_2000.tar.gz
<a href="#id15"><span class="problematic" id="id16">|</span></a>——– 00000000_1000_image
<a href="#id17"><span class="problematic" id="id18">|</span></a>——– 00000000_1000_text
<a href="#id19"><span class="problematic" id="id20">|</span></a>——– 00000000_1001_image
<a href="#id21"><span class="problematic" id="id22">|</span></a>——– 00000000_1001_text
<a href="#id23"><span class="problematic" id="id24">|</span></a>——– …</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>opts</strong> – An argparse.Namespace instance.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="data.datasets.multi_modal_img_text.img_text_tar_dataset.ImgTextTarDataset.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">opts</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="../_modules/data/datasets/multi_modal_img_text/img_text_tar_dataset.html#ImgTextTarDataset.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#data.datasets.multi_modal_img_text.img_text_tar_dataset.ImgTextTarDataset.__init__" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="data.datasets.multi_modal_img_text.img_text_tar_dataset.ImgTextTarDataset.get_dataset">
<span class="sig-name descname"><span class="pre">get_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/data/datasets/multi_modal_img_text/img_text_tar_dataset.html#ImgTextTarDataset.get_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#data.datasets.multi_modal_img_text.img_text_tar_dataset.ImgTextTarDataset.get_dataset" title="Permalink to this definition"></a></dt>
<dd><p>Reads the metadata file and returns a mapping of indices of files stored in a tar file and its name</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="data.datasets.multi_modal_img_text.img_text_tar_dataset.ImgTextTarDataset.add_arguments">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">add_arguments</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parser</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ArgumentParser</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ArgumentParser</span></span></span><a class="reference internal" href="../_modules/data/datasets/multi_modal_img_text/img_text_tar_dataset.html#ImgTextTarDataset.add_arguments"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#data.datasets.multi_modal_img_text.img_text_tar_dataset.ImgTextTarDataset.add_arguments" title="Permalink to this definition"></a></dt>
<dd><p>Add dataset-specific arguments to the parser.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="data.datasets.multi_modal_img_text.img_text_tar_dataset.ImgTextTarDataset.get_dataset_pair">
<span class="sig-name descname"><span class="pre">get_dataset_pair</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img_index</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">Tuple</span><span class="p"><span class="pre">[</span></span><span class="pre">Image</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="../_modules/data/datasets/multi_modal_img_text/img_text_tar_dataset.html#ImgTextTarDataset.get_dataset_pair"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#data.datasets.multi_modal_img_text.img_text_tar_dataset.ImgTextTarDataset.get_dataset_pair" title="Permalink to this definition"></a></dt>
<dd><p>For a given image index, read the image file, corresponding caption, and class label.
If class label is not present, -1 is returned.</p>
</dd></dl>

</dd></dl>

</section>
<section id="module-data.datasets.multi_modal_img_text">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-data.datasets.multi_modal_img_text" title="Permalink to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="data.datasets.multi_modal_img_text.arguments_multi_modal_img_text">
<span class="sig-prename descclassname"><span class="pre">data.datasets.multi_modal_img_text.</span></span><span class="sig-name descname"><span class="pre">arguments_multi_modal_img_text</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parser</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">ArgumentParser</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">ArgumentParser</span></span></span><a class="reference internal" href="../_modules/data/datasets/multi_modal_img_text.html#arguments_multi_modal_img_text"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#data.datasets.multi_modal_img_text.arguments_multi_modal_img_text" title="Permalink to this definition"></a></dt>
<dd></dd></dl>

</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Copyright (C) 2023 Apple Inc. All Rights Reserved..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>